{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furtman/WQTC25_workshop_IMTR/blob/main/Ex_geospatial/water_quality_visualization_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCW01: From Data Management to Data Analysis â€” A Technical Deep-Dive**\n",
        "AWWA WQTC 2025, November 9-13th, Tacoma WA\n",
        "## **Water Quality Data Visualization using Google Colab and Python**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook walks through building and running an interactive data visualization dashboard inside a **Google Colab** workspace using the **Python** programming language. Users will learn how to load, inspect, and analyze data from comma-separated (.csv) files, generate static and interactive visualizations of time-series plots and maps, and compile visualizations and stats into a PDF report and an easy-to-use dashboard that synthesizes data into single webpage.\n",
        "\n",
        "The water quality data used in this notebook can be downloaded directly from the Thurston County Streams Water Quality Dashboard: https://www.thurstoncountywa.gov/streams-water-quality-dashboard\n",
        "\n",
        "This link will take you to an example of a fully-functional, web-based data dashboard that was created using R (another popular programming langauge used for data science).\n"
      ],
      "metadata": {
        "id": "KoemvlApqdWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŽ Notebook Table of Contents:\n",
        "1.   Setup Python Runtime\n",
        "2.   Load Python Libraries\n",
        "3.   Upload Data Files to Google Colab\n",
        "4.   Load and Inspect Data\n",
        "5.   Data Cleaning and Processing\n",
        "6.   Generating Summary Statistics\n",
        "7.   Generating Plots\n",
        "8.   Generating Multiple Plots and PDF Reports\n",
        "9.   Generating Maps"
      ],
      "metadata": {
        "id": "uMXnR0P5WUK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ’ª Helpful keyboard shortcuts:\n",
        "*   `ctrl enter`: Runs a code cell\n",
        "*   `ctrl shift enter`: Runs a code cell and advances to next cell\n",
        "*   `ctrl shift enter w/ selection`: Runs the selected code within a code cell\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FhZ2o5yCWVoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Setup Python Runtime\n",
        "Prior to installing any libraries/packages, change the **runtime type** to **Python 3** if it isn't already selected. Google Colab comes with several popular python packages pre-installed, such as *pandas* and *matplotlib*.\n",
        "\n"
      ],
      "metadata": {
        "id": "SOwfXpnOxRtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Load Python Libraries\n",
        "In order to use the functions within each library, we need to load them into the notebook."
      ],
      "metadata": {
        "id": "iafWRDeWxpjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the Python libraries that will be used in this notebook\n",
        "# Tip: Hover over the libraries to view more info about them\n",
        "from google.colab import files                       # for uploading/downloading files in Colab\n",
        "import pandas as pd                                  # data manipulation and analysis\n",
        "import matplotlib.pyplot as plt                      # plotting static graphs\n",
        "from scipy.stats import linregress                   # linear regression and statistical functions\n",
        "import plotly.express as px                          # interactive plots and dashboards\n",
        "from matplotlib.backends.backend_pdf import PdfPages # save multiple matplotlib plots to a PDF\n",
        "import numpy as                                      # numerical operations, arrays, and math functions"
      ],
      "metadata": {
        "id": "es0shomvxxdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Upload Files to Google Colab\n",
        "Since Google Colab is run on Linux-based cloud machines, we need to transfer the files from our PC (Windows, macOS, etc.) to the Google Colab workspace. Prior to running to next code cell, download the two data files from the GitHub code repository: https://github.com/furtman/WQTC25_workshop_IMTR/tree/main/Ex_geospatial/Data"
      ],
      "metadata": {
        "id": "qNz11c3KpuLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose files to upload; By default, uploaded files are saved in the \"Files/content/\" folder within the Google Colab workspace\n",
        "# from google.colab import files\n",
        "uploaded_files = files.upload()"
      ],
      "metadata": {
        "id": "uIPbdrlFsAmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Load and Inspect Data\n",
        "Read in the CSV files to the notebook as variables called `sites` and `wq_data`."
      ],
      "metadata": {
        "id": "rbpSAyCQyR_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in stream site location data and inspect\n",
        "# import pandas as pd\n",
        "sites = pd.read_csv(\"streams_sites.csv\")\n",
        "print('This is the stream site location data:') # output a message to the console\n",
        "sites # show data"
      ],
      "metadata": {
        "id": "otTeWFqL57d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Task 1: Read in water quality data and inspect"
      ],
      "metadata": {
        "id": "zCPjvQ1xM3bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Read in water quality data as a variable named \"wq_data\"\n",
        "wq_data = pd.read_csv(\"wqp_data.csv\")\n",
        "print(\"This is the water quality data associated with each stream site:\")\n",
        "wq_data"
      ],
      "metadata": {
        "id": "Y0Xt-Hwb5vM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show some general info about the data types of each column in the water quality data\n",
        "wq_data.info()"
      ],
      "metadata": {
        "id": "y6z_WWzZf5C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the unique stream site locations and parameter names\n",
        "print(\"The unique stream site locations are:\", sites['SITE_NAME'].unique())\n",
        "print(\"\\n\") # add a line break so it's easier to see the different outputs\n",
        "print(\"The unique parameter names are:\", wq_data['parameter'].unique())"
      ],
      "metadata": {
        "id": "O19q3WhprM_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Data Cleaning and Processing"
      ],
      "metadata": {
        "id": "UFsRaVj57jEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct timeseries analysis and plot the WQ data, we need to change the 'date_time' column to a datetime data type and sort by date\n",
        "wq_data['date_time_new'] = pd.to_datetime(wq_data['date_time'], format='mixed')\n",
        "wq_data = wq_data.sort_values(by='date_time_new') # sort values by datetime\n",
        "wq_data.info()"
      ],
      "metadata": {
        "id": "KYGA65zy7l66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct geospatial analysis and generate maps, we need to join/merge the WQ data with the stream site location data\n",
        "merged_data = pd.merge(\n",
        "    wq_data,\n",
        "    sites[['SITE_NAME', 'LAT', 'LON', 'AquaticLifeUse']], # keep only the site name, latitude, longitude, and aquatic life use columns\n",
        "    on='SITE_NAME', # merge the dataframes based on a common column\n",
        "    how='left' # keep all rows in the wq_data and only matching rows in the sites data\n",
        ")\n",
        "\n",
        "merged_data.columns # show the dataframe column names"
      ],
      "metadata": {
        "id": "3A1pkzcO8QVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Generating Summary Statistics"
      ],
      "metadata": {
        "id": "8A1EWwgS2J8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some basic summary stats of observed WQ values for each site and parameter pairing\n",
        "summary_stats = merged_data.groupby(['SITE_NAME', 'parameter'])['value'].agg(['count','mean','median','min','max']).reset_index()\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "CJzv-GeB2JpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View summary stats for a specific site\n",
        "summary_stats[summary_stats['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park']"
      ],
      "metadata": {
        "id": "j0I6ddDJ49kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 7. Generating Plots"
      ],
      "metadata": {
        "id": "Zk0IV2l1A38G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Static Plots"
      ],
      "metadata": {
        "id": "UV_iYU_lnptV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a timeseries plot of a WQ parameter for a specific site\n",
        "\n",
        "# Filter the data for a specific site name and parameter (e.g., water temperature)\n",
        "site_name = 'Deschutes @ Tumwater Falls Park'\n",
        "param_name = 'Temperature, water'\n",
        "\n",
        "site_temp_data = merged_data[ # filter out data for specific parameter and site\n",
        "    (merged_data['SITE_NAME'] == site_name) &\n",
        "    (merged_data['parameter'] == param_name)\n",
        "    ].copy() # save to a new dataframe\n",
        "\n",
        "site_temp_data = site_temp_data.sort_values(by='date_time_new') # sort the data by date/time\n",
        "site_temp_data"
      ],
      "metadata": {
        "id": "gg-mR-M26xv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic line plot\n",
        "# import matplotlib.pyplot as plt\n",
        "plt.plot(site_temp_data['date_time_new'], site_temp_data['value']) # x, y\n",
        "plt.xlabel('Date') # x-axis label\n",
        "plt.ylabel(param_name) # y-axis label\n",
        "plt.title(site_name) # plot title\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eSzXstxzCnTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Even fancier plot with summary stats and trend line\n",
        "# from scipy.stats import linregress\n",
        "\n",
        "# Convert temperature from C to F\n",
        "site_temp_data['value_F'] = site_temp_data['value'] * 9/5 + 32\n",
        "\n",
        "# Calculate stats\n",
        "mean_temp = site_temp_data['value_F'].mean()\n",
        "min_temp = site_temp_data['value_F'].min()\n",
        "max_temp = site_temp_data['value_F'].max()\n",
        "\n",
        "# Linear regression for trend\n",
        "# x as ordinal dates\n",
        "x = site_temp_data['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "y = site_temp_data['value_F']\n",
        "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "# Calculate trend line y values\n",
        "slope_per_year = slope * 365.25 # convert to per year\n",
        "trend_line = slope * x + intercept\n",
        "\n",
        "# Compute RÂ² and p-value significance\n",
        "r_squared = r_value ** 2\n",
        "if p_value < 0.05:\n",
        "  significance = \"Significant (p < 0.05)\"\n",
        "else:\n",
        "  significance = \"Not Significant (p > 0.05)\"\n",
        "#significance = \"Significant\" if p_value < 0.05 else \"Not Significant\" # how the cool kids do it\n",
        "\n",
        "# List of stats that will be added to the plot\n",
        "stats_text = (\n",
        "    f\"Max: {max_temp:.1f}Â°F\\n\"\n",
        "    f\"Min: {min_temp:.1f}Â°F\\n\"\n",
        "    f\"Mean: {mean_temp:.1f}Â°F\\n\"\n",
        "    f\"Trend slope: {slope_per_year:.3f}Â°F/year\\n\"\n",
        "    f\"RÂ²: {r_squared:.3f}\\n\"\n",
        "    f\"p-value: {p_value:.4f}\\n\"\n",
        "    f\"{significance}\"\n",
        ")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14, 6)) # width, height\n",
        "plt.plot(site_temp_data['date_time_new'], site_temp_data['value_F'], # x, y\n",
        "         marker='o', markersize=3, # marker style\n",
        "         linestyle='-', linewidth=1, # line style\n",
        "         label='Observed Data') # legend label\n",
        "plt.plot(site_temp_data['date_time_new'], trend_line, # trend line\n",
        "         linestyle='--', linewidth=2, color='red', # line style\n",
        "         label='Trend Line') # legend label\n",
        "\n",
        "# Add stats to plot\n",
        "plt.text(0.01, 0.98, stats_text, transform=plt.gca().transAxes,\n",
        "         verticalalignment='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
        "\n",
        "# Plot beautification\n",
        "plt.grid(True, linestyle='--', alpha=0.8) # background grid\n",
        "plt.title(f'{param_name} at {site_name}', fontsize=14, fontweight='bold') # plot title\n",
        "plt.ylabel(\"Water Temperature (Â°F)\", fontsize=12) # y-axis label\n",
        "plt.xticks(rotation=45) # rotate the x-axis labels\n",
        "plt.legend() # add legend\n",
        "plt.tight_layout() # auto adjust spacing to prevent overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UDp-W8g_IWmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Plots"
      ],
      "metadata": {
        "id": "0qv2PiizniMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a basic interactive plot of water temperature at every site on the Deschutes River\n",
        "# import plotly.express as px\n",
        "\n",
        "# Filter water temperature data and site names that begin with \"Deschutes\"\n",
        "filtered_data = merged_data[\n",
        "    (merged_data['parameter'] == param_name) & # 'Temperature, water'\n",
        "    (merged_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ].copy()\n",
        "\n",
        "# Sort by datetime\n",
        "filtered_data = filtered_data.sort_values(by='date_time_new')\n",
        "\n",
        "# Plotting\n",
        "fig = px.line(\n",
        "    filtered_data,\n",
        "    x='date_time_new', # x data\n",
        "    y='value', # y data\n",
        "    color='SITE_NAME', # symbolize site name by color\n",
        "    title='Deschutes River Water Temperature'\n",
        ")\n",
        "\n",
        "# Layout styling for comparison\n",
        "fig.update_layout(hovermode='x unified') # enables value hovering for easy comparison\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0N9AiFH9n5-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy interactive plot of all WQ parameters at every site on the Deschutes River\n",
        "\n",
        "# Filter site names that begin with \"Deschutes\" and sort by datetime\n",
        "deschutes_data = merged_data[\n",
        "    (merged_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ].sort_values(by='date_time_new').copy()\n",
        "\n",
        "# Plotting\n",
        "fig_deschutes = px.line(\n",
        "    deschutes_data,\n",
        "    x='date_time_new',\n",
        "    y='value',\n",
        "    color='SITE_NAME',\n",
        "    facet_col='parameter', # each parameter gets its own plot\n",
        "    facet_col_wrap=3, # 3 plots per row\n",
        "    title='Deschutes River Water Quality Parameters',\n",
        "    height=800, # figure height\n",
        "    labels={ # customize label names for data hover\n",
        "        'date_time_new': 'Date',\n",
        "        'value': 'Measured Value',\n",
        "        'SITE_NAME': 'Site Name',\n",
        "        'unit': 'Unit'\n",
        "    },\n",
        "    hover_data={ # customize label values for data hover\n",
        "        'date_time_new': '|%m-%d-%Y', # reformat the datetime to mm/dd/yyyy\n",
        "        'value': ':.2f', # value with 2 decimals\n",
        "        'SITE_NAME': True, # inlcude site name in hover\n",
        "        'unit': True,\n",
        "        'parameter': False # do not include parameter name in hover\n",
        "    }\n",
        ")\n",
        "\n",
        "# Improve layout styling\n",
        "fig_deschutes.update_layout(\n",
        "    hovermode='x unified',\n",
        "    showlegend=True,\n",
        "    legend_title_text='Site Name', # update the legend title\n",
        "    title_font_size=18, # adjust plot title font size\n",
        "    margin=dict(l=40, r=40, t=80, b=40) # adjust plot margins (left, right, top, bottom)\n",
        ")\n",
        "\n",
        "# Make each facet plot's y-axis values independent from each other (needed since parameters have different measurement units)\n",
        "fig_deschutes.update_yaxes(title='', matches=None) # don't show y-axis label\n",
        "fig_deschutes.update_xaxes(title='') # don't show x-axis label\n",
        "\n",
        "# Clean up facet titles: remove \"parameter_unit=\" prefix\n",
        "for annotation in fig_deschutes.layout.annotations:\n",
        "    annotation.text = annotation.text.replace(\"parameter=\", \"\")\n",
        "\n",
        "fig_deschutes.show()"
      ],
      "metadata": {
        "id": "DJHMkoWlY2dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Generating Multiple Plots and PDF Reports\n",
        "Up until this point, Excel would have been able to handle everything we just did (i.e., look at the data, filter by parameter and site, create plots). With Python (and programming in general), we can take this a step further by automating those redundant processes that are done in Excel. For example, we can write a script to plot a timeseries of all WQ parameters at each stream site location and then save to a PDF."
      ],
      "metadata": {
        "id": "-AzNrsKU-zys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy, multi-facet plot of all WQ parameters for each stream site location and save to a single PDF (takes approx. 4-5 minutes to run)\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# import numpy as np\n",
        "\n",
        "# Toggle switch for running the cell\n",
        "run_cell = False # True or False\n",
        "\n",
        "# Output file\n",
        "output_pdf = \"WaterQuality_SiteParameter_Trends.pdf\"\n",
        "\n",
        "if run_cell:\n",
        "  # Create PDF file to save all plots; each site gets a single PDF page\n",
        "  with PdfPages(output_pdf) as pdf:\n",
        "      # Loop through each site\n",
        "      for site_name, site_df in merged_data.groupby('SITE_NAME'):\n",
        "          parameters = site_df['parameter'].unique()\n",
        "\n",
        "          # Setup multi-facet plot layout\n",
        "          n_params = len(parameters)\n",
        "          ncols = 2\n",
        "          nrows = int(np.ceil(n_params / ncols))\n",
        "          fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, nrows * 4))\n",
        "          axes = axes.flatten()\n",
        "\n",
        "          # Loop through each parameter, apply regression, calculate stats, and plot\n",
        "          for i, param_name in enumerate(parameters):\n",
        "              ax = axes[i]\n",
        "              param_df = site_df[site_df['parameter'] == param_name].copy()\n",
        "              param_df = param_df.sort_values(by=\"date_time_new\")\n",
        "\n",
        "              # Convert temperature from C to F\n",
        "              if \"temp\" in param_name.lower():\n",
        "                  param_df['value_plot'] = param_df['value'] * 9/5 + 32\n",
        "                  y_label = \"Temperature (Â°F)\"\n",
        "              else:\n",
        "                  param_df['value_plot'] = param_df['value']\n",
        "                  y_label = f\"{param_name} ({param_df['unit'].iloc[0] if 'unit' in param_df.columns else ''})\"\n",
        "\n",
        "              # Data for regression\n",
        "              param_df = param_df.dropna(subset=['date_time_new', 'value_plot']) # remove NA values for regression analysis\n",
        "              x = param_df['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "              y = param_df['value_plot']\n",
        "              n_points = len(y)\n",
        "\n",
        "              # Check data sufficiency\n",
        "              if n_points >= 3:\n",
        "                  slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "                  slope_per_year = slope * 365.25\n",
        "                  r_squared = r_value ** 2\n",
        "                  trend_line = slope * x + intercept\n",
        "                  significance = \"Significant (p < 0.05)\" if p_value < 0.05 else \"Not Significant\"\n",
        "              else:\n",
        "                  slope_per_year = np.nan\n",
        "                  r_squared = np.nan\n",
        "                  p_value = np.nan\n",
        "                  trend_line = [np.nan] * len(x)\n",
        "                  significance = \"Insufficient data for regression\"\n",
        "\n",
        "              # Summary statistics\n",
        "              mean_val = y.mean()\n",
        "              min_val = y.min()\n",
        "              max_val = y.max()\n",
        "\n",
        "              # Stats text\n",
        "              if np.isnan(p_value):\n",
        "                  p_str = \"N/A\"\n",
        "              else:\n",
        "                  p_str = f\"{p_value:.4f}\"\n",
        "\n",
        "              stats_text = (\n",
        "                  f\"n = {n_points}\\n\"\n",
        "                  f\"Max: {max_val:.1f}\\n\"\n",
        "                  f\"Min: {min_val:.1f}\\n\"\n",
        "                  f\"Mean: {mean_val:.1f}\\n\"\n",
        "                  f\"Trend: {slope_per_year:.3f}/yr\\n\"\n",
        "                  f\"RÂ²: {r_squared:.3f}\\n\"\n",
        "                  f\"p: {p_str}\\n\"\n",
        "                  f\"{significance}\"\n",
        "              )\n",
        "\n",
        "              # Plotting\n",
        "              ax.plot(param_df['date_time_new'], y, marker='o', markersize=3,\n",
        "                      linestyle='-', linewidth=1, label='Observed')\n",
        "              ax.plot(param_df['date_time_new'], trend_line, linestyle='--',\n",
        "                      linewidth=2, color='red', label='Trend')\n",
        "              ax.text(0.01, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
        "                      verticalalignment='top',\n",
        "                      bbox=dict(facecolor='white', alpha=0.7, edgecolor='gray'))\n",
        "              ax.set_title(f\"{param_name}\", fontsize=11, fontweight='bold')\n",
        "              ax.set_ylabel(y_label)\n",
        "              ax.grid(True, linestyle='--', alpha=0.6)\n",
        "              ax.legend(fontsize=8)\n",
        "              ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "          # Remove unused subplots\n",
        "          for j in range(i + 1, len(axes)):\n",
        "              fig.delaxes(axes[j])\n",
        "\n",
        "          # Layout and save\n",
        "          fig.suptitle(f\"Water Quality Trends at {site_name}\", fontsize=14, fontweight='bold')\n",
        "          plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "          pdf.savefig(fig)\n",
        "          plt.close(fig)\n",
        "\n",
        "  print(f\"All plots saved to: {output_pdf}\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping this cell.\")"
      ],
      "metadata": {
        "id": "Ps1mxoxuRM9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 9. Generating Maps\n",
        "Since the stream site location data has a latitude and longitude column, we can plot the locations on an interactive map."
      ],
      "metadata": {
        "id": "kQESUKPdQRWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a basic location map of stream site locations\n",
        "\n",
        "site_map = px.scatter_mapbox(\n",
        "    sites, # stream site location data\n",
        "    lat=\"LAT\", # latitude column\n",
        "    lon=\"LON\", # longitude column\n",
        "    hover_name=\"SITE_NAME\", # popup label that appears when hovered over\n",
        "    hover_data=\"AquaticLifeUse\", # popup data that appears when hovered over\n",
        "    title=\"Stream Site Monitoring Locations\", # map title\n",
        "    mapbox_style=\"open-street-map\", # basemap; other options - \"carto-positron\", \"carto-darkmatter\"\n",
        ")\n",
        "\n",
        "site_map.show(config={'scrollZoom': True}) # show map (and enable scroll zoom for convience)"
      ],
      "metadata": {
        "id": "krq2jU1waXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a map showing the distribution of water temperature at stream site locations\n",
        "\n",
        "# Filter out stream temperature data\n",
        "stream_temp_data = merged_data[\n",
        "    (merged_data['parameter'] == param_name) # 'Temperature, water'\n",
        "    ].copy()\n",
        "\n",
        "# Calculate monthly average stream temperature for all sites\n",
        "stream_temp_data[\"year_month\"] = stream_temp_data[\"date_time_new\"].dt.to_period(\"M\").dt.strftime(\"%Y-%m\") # add a year_month column so we can group by month\n",
        "monthly_avg_temp = (\n",
        "    stream_temp_data\n",
        "    .groupby([\"SITE_NAME\", \"LAT\", \"LON\", \"year_month\", \"parameter\", \"unit\"], as_index=False)\n",
        "    .agg(mean_temp=(\"value\", \"mean\"))\n",
        ").sort_values(by=\"year_month\")\n",
        "\n",
        "# Find min and max stream temperautre values\n",
        "vmin = monthly_avg_temp['mean_temp'].min()\n",
        "vmax = monthly_avg_temp['mean_temp'].max()\n",
        "\n",
        "# Plotting\n",
        "stream_temp_map = px.scatter_mapbox(\n",
        "    monthly_avg_temp,\n",
        "    lat=\"LAT\",\n",
        "    lon=\"LON\",\n",
        "    color=\"mean_temp\", # symbolize points by stream temp value\n",
        "    range_color=(vmin, vmax), # color range based on min/max temp values\n",
        "    animation_frame=\"year_month\", # animate points by date/time\n",
        "    hover_name=\"SITE_NAME\",\n",
        "    hover_data={\n",
        "        \"year_month\": \"|%Y-%m\", # show datetime in hover\n",
        "        \"parameter\": True, # show parameter\n",
        "        \"mean_temp\": \":.2f\", # show value with 2 decimals\n",
        "        \"unit\": True, # show parameter unit\n",
        "        \"LAT\": False, # DO NOT show LAT\n",
        "        \"LON\": False # DO NOT show LONG\n",
        "    },\n",
        "    title=\"Stream Temperature at Monitoring Locations in Thurston County\",\n",
        "    height=800, # map height\n",
        "    zoom=9, # set zoom level\n",
        "    mapbox_style=\"carto-positron\" # better basemap for viewing symbol colors\n",
        ")\n",
        "\n",
        "# Update map aesthetics\n",
        "stream_temp_map.update_traces(marker=dict(size=12)) # increase size of points on map\n",
        "\n",
        "stream_temp_map.show(config={'scrollZoom': True}) # show map (and enable scroll zoom for convience)"
      ],
      "metadata": {
        "id": "dSi3NOMVv5Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 10. Generating Data Dashboards"
      ],
      "metadata": {
        "id": "Ay9LplAga8fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages that aren't preinstalled in Colab\n",
        "!pip install dash\n",
        "\n",
        "from dash import Dash, dcc, html, Input, Output"
      ],
      "metadata": {
        "id": "NqN9Hv9BN2vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Generate a data dashboard\n",
        "\n",
        "# Get unique parameter names and sort alphabetically\n",
        "param_options = sorted(merged_data[\"parameter\"].dropna().unique())\n",
        "\n",
        "# Initialize the app\n",
        "app = Dash(__name__)\n",
        "\n",
        "# App layout (User-Interface) --------------------------------------------------\n",
        "app.layout = html.Div([\n",
        "    # Dropdown menu\n",
        "    html.Div([\n",
        "        html.Label(\"Select Parameter:\", style={\"fontWeight\": \"bold\"}),\n",
        "        dcc.Dropdown(\n",
        "            id=\"param\",\n",
        "            options=[{\"label\": p, \"value\": p} for p in param_options],\n",
        "            value=param_options[0],\n",
        "            clearable=False,\n",
        "            style={\"width\": \"100%\"}\n",
        "        ),\n",
        "    ], style={\"width\": \"25%\", \"margin\": \"10px\"}),\n",
        "\n",
        "    # Time-Series Plot and Map\n",
        "    html.Div([\n",
        "        html.Div([\n",
        "            dcc.Graph(\n",
        "                id=\"timeseries\",\n",
        "                style={\"width\": \"100%\", \"height\": \"90vh\"},\n",
        "                config={\"responsive\": True}\n",
        "            )\n",
        "        ], style={\"flex\": \"1.5\"}),\n",
        "\n",
        "        html.Div([\n",
        "            dcc.Graph(\n",
        "                id=\"map\",\n",
        "                style={\"width\": \"100%\", \"height\": \"90vh\"},\n",
        "                config={\"responsive\": True}\n",
        "            )\n",
        "        ], style={\"flex\": \"1\"})\n",
        "    ], style={\n",
        "        \"display\": \"flex\",\n",
        "        \"flexDirection\": \"row\",\n",
        "        \"width\": \"100%\",\n",
        "        \"alignItems\": \"stretch\",\n",
        "    })\n",
        "])\n",
        "\n",
        "# Callback to update plot and map ----------------------------------------------\n",
        "@app.callback(\n",
        "    Output(\"timeseries\", \"figure\"),\n",
        "    Output(\"map\", \"figure\"),\n",
        "    Input(\"param\", \"value\")\n",
        ")\n",
        "\n",
        "# Update plot and map based on user selection from dropdown menu\n",
        "def update_dashboard(param):\n",
        "    df = merged_data[merged_data[\"parameter\"] == param].copy()\n",
        "    df[\"year_month_dt\"] = df[\"date_time_new\"].dt.to_period(\"M\").dt.to_timestamp()\n",
        "    df[\"year_month\"] = df[\"date_time_new\"].dt.strftime(\"%Y-%m\")\n",
        "\n",
        "    # Monthly averages\n",
        "    monthly_avg = (\n",
        "        df.groupby([\"SITE_NAME\", \"LAT\", \"LON\", \"year_month\", \"year_month_dt\"], as_index=False)\n",
        "          .agg(mean_value=(\"value\", \"mean\"))\n",
        "          .sort_values(\"year_month_dt\")\n",
        "    )\n",
        "\n",
        "    ## Time-series line plot ---------------------------------------------------\n",
        "    ts_fig = px.line(\n",
        "        monthly_avg, x=\"year_month\", y=\"mean_value\", color=\"SITE_NAME\",\n",
        "        title=f\"{param} â€” Monthly Trend by Site\", height=800,\n",
        "        category_orders={\"SITE_NAME\": sorted(monthly_avg[\"SITE_NAME\"].unique())}\n",
        "    )\n",
        "    ts_fig.update_layout(\n",
        "        autosize=True,\n",
        "        xaxis_title=\"\",\n",
        "        margin=dict(t=50, l=20, r=20, b=100),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"top\",\n",
        "            y=-0.2,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5,\n",
        "            title=None,\n",
        "            font=dict(size=10)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    ## Map (animated) ----------------------------------------------------------\n",
        "    vmin, vmax = monthly_avg[\"mean_value\"].min(), monthly_avg[\"mean_value\"].max() # min and max of parameter data\n",
        "\n",
        "    # Plotting\n",
        "    map_fig = px.scatter_mapbox(\n",
        "        monthly_avg, lat=\"LAT\", lon=\"LON\", color=\"mean_value\",\n",
        "        range_color=(vmin, vmax), animation_frame=\"year_month_dt\",\n",
        "        hover_name=\"SITE_NAME\", mapbox_style=\"carto-positron\",\n",
        "        zoom=8, height=800\n",
        "    )\n",
        "    map_fig.update_traces(marker=dict(size=12))\n",
        "    map_fig.update_layout(\n",
        "        autosize=True,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"top\",\n",
        "            y=0,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5,\n",
        "            title=None\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return ts_fig, map_fig\n",
        "\n",
        "# Run app ----------------------------------------------------------------------\n",
        "app.run(mode=\"inline\") # run app within Colab"
      ],
      "metadata": {
        "id": "9hv2Q7SyOIsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}