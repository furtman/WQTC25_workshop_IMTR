{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furtman/WQTC25_workshop_IMTR/blob/main/Ex_geospatial/water_quality_visualization_Python_ANSWERS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCW01: From Data Management to Data Analysis â€” A Technical Deep-Dive**\n",
        "AWWA WQTC 2025, November 9-13th, Tacoma WA\n",
        "## **Water Quality Data Visualization using Google Colab and Python**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook walks through building and running an interactive data visualization dashboard inside a **Google Colab** workspace using the **Python** programming language. Users will learn how to load, inspect, and analyze data from comma-separated (.csv) files, generate static and interactive visualizations of time-series plots and maps, and compile visualizations and stats into a PDF report and an easy-to-use dashboard that synthesizes data into single webpage.\n",
        "\n",
        "The water quality data used in this notebook can be downloaded directly from the Thurston County Streams Water Quality Dashboard: https://www.thurstoncountywa.gov/streams-water-quality-dashboard\n",
        "\n",
        "This link will take you to an example of a fully-functional, web-based data dashboard that was created using R (another popular programming langauge used for data science).\n"
      ],
      "metadata": {
        "id": "KoemvlApqdWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŽ Notebook Table of Contents:\n",
        "1.   Setup Python Runtime\n",
        "2.   Load Python Libraries\n",
        "3.   Upload Data Files to Google Colab\n",
        "4.   Load and Inspect Data\n",
        "5.   Data Cleaning and Processing\n",
        "6.   Generating Summary Statistics\n",
        "7.   Generating Plots\n",
        "8.   Automating Plot Generation and PDF Reports\n",
        "9.   Generating Maps\n",
        "10.  Generating Data Dashboards"
      ],
      "metadata": {
        "id": "uMXnR0P5WUK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ’ª Helpful keyboard shortcuts:\n",
        "*   `ctrl enter`: Runs a code cell\n",
        "*   `ctrl shift enter`: Runs a code cell and advances to next cell\n",
        "*   `ctrl shift enter w/ selection`: Runs the selected code within a code cell\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FhZ2o5yCWVoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Setup Python Runtime\n",
        "Prior to installing any libraries/packages, change the **runtime type** to **Python 3** if it isn't already selected. Google Colab comes with several popular python packages pre-installed, such as *pandas* and *matplotlib*.\n",
        "\n"
      ],
      "metadata": {
        "id": "SOwfXpnOxRtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Load Python Libraries\n",
        "In order to use the functions within each library, we need to load them into the notebook."
      ],
      "metadata": {
        "id": "iafWRDeWxpjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the Python libraries that will be used in this notebook\n",
        "# Tip: Hover over the libraries to view more info about them\n",
        "\n",
        "from google.colab import files                       # for uploading/downloading files in Colab\n",
        "import pandas as pd                                  # data manipulation and analysis\n",
        "import matplotlib.pyplot as plt                      # plotting static graphs\n",
        "from scipy.stats import linregress                   # linear regression and statistical functions\n",
        "import plotly.express as px                          # interactive plots and dashboards\n",
        "from matplotlib.backends.backend_pdf import PdfPages # save multiple matplotlib plots to a PDF\n",
        "import numpy as np                                   # numerical operations, arrays, and math functions"
      ],
      "metadata": {
        "id": "es0shomvxxdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Upload Files to Google Colab\n",
        "Since Google Colab is run on Linux-based cloud machines, we need to transfer the files from our PC (Windows, macOS, etc.) to the Google Colab workspace. Prior to running the next code cell, download the two data files from the GitHub code repository: https://github.com/furtman/WQTC25_workshop_IMTR/tree/main/Ex_geospatial/Data"
      ],
      "metadata": {
        "id": "qNz11c3KpuLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose files to upload; By default, uploaded files are saved in the \"Files/content/\" folder within the Google Colab workspace\n",
        "# from google.colab import files\n",
        "\n",
        "uploaded_files = files.upload()"
      ],
      "metadata": {
        "id": "uIPbdrlFsAmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Load and Inspect Data\n",
        "Read in the CSV files to the notebook as variables called `sites` and `wq_data`."
      ],
      "metadata": {
        "id": "rbpSAyCQyR_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in stream site location data and inspect\n",
        "# import pandas as pd\n",
        "\n",
        "sites = pd.read_csv(\"streams_sites.csv\")\n",
        "sites # show data"
      ],
      "metadata": {
        "id": "otTeWFqL57d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show some general info about the data types of each column in the stream site data\n",
        "sites.info()"
      ],
      "metadata": {
        "id": "D7XKaMrtsA3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data within a specific column, such as SITE_NAME\n",
        "sites['SITE_NAME']"
      ],
      "metadata": {
        "id": "NB75mwa2tPEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View each stream site name using the unique() function\n",
        "sites['SITE_NAME'].unique()"
      ],
      "metadata": {
        "id": "rcKLak6Pu3LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for a specific stream site location, such as Deschutes @ Tumwater Falls Park\n",
        "sites[sites['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park']"
      ],
      "metadata": {
        "id": "xGBrYd8xzmDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Task 1: Read in water quality data and inspect"
      ],
      "metadata": {
        "id": "zCPjvQ1xM3bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T1.1: Read in water quality data as a variable named \"wq_data\" and inspect\n",
        "wq_data = pd.read_csv(\"wqp_data.csv\")\n",
        "wq_data.info()\n",
        "wq_data"
      ],
      "metadata": {
        "id": "Y0Xt-Hwb5vM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T1.2: Show the unique water quality parameter names\n",
        "print(\"The unique parameter names are:\", wq_data['parameter'].unique())"
      ],
      "metadata": {
        "id": "O19q3WhprM_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T1.3: Filter the water quality data for Temperature, water at the Deschutes @ Tumwater Falls Park\n",
        "wq_data[(wq_data['parameter'] == 'Temperature, water') & (wq_data['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park')]"
      ],
      "metadata": {
        "id": "nF7a_4qF0vS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to visualize the above data by creating a time-series plot of temperature\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign the filtered data to a variable\n",
        "deschutes_temp_data = wq_data[(wq_data['parameter'] == 'Temperature, water') & (wq_data['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park')]\n",
        "\n",
        "# Create a time-series plot\n",
        "plt.plot(deschutes_temp_data['date_time'], deschutes_temp_data['value']) # x, y\n",
        "plt.show()\n",
        "\n",
        "# T1.4: What's wrong with the plot?"
      ],
      "metadata": {
        "id": "po9wmHbV3MpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Data Cleaning and Processing"
      ],
      "metadata": {
        "id": "UFsRaVj57jEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct timeseries analysis and plot the WQ data, we need to change the 'date_time' column to a datetime data type\n",
        "wq_data['date_time_new'] = pd.to_datetime(wq_data['date_time'], format='mixed')\n",
        "wq_data = wq_data.sort_values(by='date_time_new') # sort values by datetime\n",
        "wq_data.info()"
      ],
      "metadata": {
        "id": "KYGA65zy7l66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data with the date_time_new column\n",
        "deschutes_temp_data = wq_data[(wq_data['parameter'] == 'Temperature, water') & (wq_data['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park')].copy()\n",
        "\n",
        "# Create a time-series plot\n",
        "plt.plot(deschutes_temp_data['date_time_new'], deschutes_temp_data['value']) # x, y\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "otDT4a758Oyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Generating Summary Statistics"
      ],
      "metadata": {
        "id": "8A1EWwgS2J8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prior to generating stats, NA or blank values need to be removed from the dataframe so they aren't included in the stats\n",
        "rows_before = len(wq_data)\n",
        "print(f\"Rows before: {rows_before}\")\n",
        "\n",
        "# Remove NA values from value column\n",
        "wq_data = wq_data.dropna(subset=['value'])\n",
        "\n",
        "rows_after = len(wq_data)\n",
        "print(f\"Rows after: {rows_after}\")\n",
        "print(f\"Rows removed: {rows_before - rows_after}\")"
      ],
      "metadata": {
        "id": "9RTWOEMu-s2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate summary stats from the deschutes_temp_data variable (Stream temperature @ Deschutes River Tumwater Falls Park)\n",
        "print(f'Location: {deschutes_temp_data['SITE_NAME'].unique()[0]}')\n",
        "print(f'Parameter: {deschutes_temp_data['parameter'].unique()[0]} ({deschutes_temp_data['unit'].unique()[0]})')\n",
        "print(f'Number of observations: {len(deschutes_temp_data)}')\n",
        "print(f'Min: {deschutes_temp_data['value'].min()}')\n",
        "print(f'Max: {deschutes_temp_data['value'].max()}')\n",
        "print(f'Mean: {deschutes_temp_data['value'].mean()}')"
      ],
      "metadata": {
        "id": "aucRUk3YDD_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from C to F and generate summary stats from the temp_data variable (Stream temperature @ Deschutes River Tumwater Falls Park)\n",
        "deschutes_temp_data['value_F'] = deschutes_temp_data['value'] * 9/5 + 32\n",
        "\n",
        "print(f'Location: {deschutes_temp_data['SITE_NAME'].unique()[0]}')\n",
        "print(f'Parameter: {deschutes_temp_data['parameter'].unique()[0]} (\\u00B0F)')\n",
        "print(f'Number of observations: {len(deschutes_temp_data)}')\n",
        "print(f'Min: {round(deschutes_temp_data['value_F'].min())}')\n",
        "print(f'Max: {round(deschutes_temp_data['value_F'].max())}')\n",
        "print(f'Mean: {round(deschutes_temp_data['value_F'].mean())}')"
      ],
      "metadata": {
        "id": "uyKSBuvLPA--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some basic summary stats of observed WQ values for each site and parameter pairing\n",
        "summary_stats = wq_data.groupby(['SITE_NAME', 'parameter'])['value'].agg(['count','mean','median','min','max']).reset_index()\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "CJzv-GeB2JpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View summary stats for a specific site\n",
        "summary_stats[summary_stats['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park']"
      ],
      "metadata": {
        "id": "j0I6ddDJ49kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Task 2: Identify outliers in wq_data at Deschutes @ Tumwater Falls Park"
      ],
      "metadata": {
        "id": "uu2BjLqKccAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# T2.1: Filter wq_data for Deschutes @ Tumwater Falls Park\n",
        "deschutes_tmf_data = wq_data[wq_data['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park'].copy()"
      ],
      "metadata": {
        "id": "Rdw3U9j-eUBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T2.2: Create a variable that contains all the unique parameter names in filtered deschutes data\n",
        "parameters = deschutes_tmf_data['parameter'].unique()"
      ],
      "metadata": {
        "id": "-pb3xBFDk7EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a for loop to calculate quartiles and IQR for each parameter\n",
        "for param in parameters:\n",
        "  print(f\"\\n{'='*60}\")\n",
        "  print(f\"Parameter: {param}\")\n",
        "  param_data = deschutes_tmf_data[deschutes_tmf_data['parameter'] == param].copy() # T2.3: XXX - Filter data for a parameter\n",
        "\n",
        "  # Calculate quartiles and IQR\n",
        "  Q1 = param_data['value'].quantile(0.25) #T2.4: XXX - Calculate quartiles for parameter values\n",
        "  Q3 = param_data['value'].quantile(0.75) #T2.5: XXX - Calculate quartiles for parameter values\n",
        "  IQR = Q3 - Q1\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "  # Identify outliers\n",
        "  outliers = param_data[\n",
        "      (param_data['value'] < lower_bound) | (param_data['value'] > upper_bound) #T2.6: XXX - Identify parameter value outliers\n",
        "  ]\n",
        "\n",
        "  # Print results\n",
        "  print(f\"Q1 = {Q1:.2f}, Q3 = {Q3:.2f}, IQR = {IQR:.2f}\")\n",
        "  print(f\"Lower bound = {lower_bound:.2f}, Upper bound = {upper_bound:.2f}\")\n",
        "  print(f\"Number of outliers = {len(outliers)}\")\n"
      ],
      "metadata": {
        "id": "ElIOZ_eNkUBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 7. Generating Plots"
      ],
      "metadata": {
        "id": "Zk0IV2l1A38G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statisical Summary Plots\n",
        "In addition to calculating quartiles and identifying outliers, we can also plot the data's distribution."
      ],
      "metadata": {
        "id": "IBXZescJbVlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic boxplot\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter pH data\n",
        "deschutes_pH_data = deschutes_tmf_data[deschutes_tmf_data['parameter'] == 'pH'][['value']]\n",
        "\n",
        "plt.boxplot(deschutes_pH_data['value'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O_fTXcDCbhuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic histogram\n",
        "plt.hist(deschutes_pH_data['value'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JrtrrgHTtOVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time-Series Plots"
      ],
      "metadata": {
        "id": "UV_iYU_lnptV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic line plot\n",
        "plt.plot(deschutes_temp_data['date_time_new'], deschutes_temp_data['value_F']) # x, y\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gg-mR-M26xv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic line plot but a little fancy\n",
        "plt.figure(figsize=(14, 6)) # width, height\n",
        "plt.plot(deschutes_temp_data['date_time_new'], deschutes_temp_data['value_F'], # x, y\n",
        "         marker='o', markersize=3, # marker style\n",
        "         linestyle='-', linewidth=1) # line style\n",
        "plt.xlabel('Date') # x-axis label\n",
        "plt.ylabel('Temperature, water (\\u00B0F)') # y-axis label\n",
        "plt.title('Deschutes @ Tumwater Falls Park') # plot title\n",
        "plt.grid(True, linestyle='--', alpha=0.8) # background grid\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eSzXstxzCnTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Even fancier plot with summary stats and trend line\n",
        "# from scipy.stats import linregress\n",
        "\n",
        "# Location and parameter name\n",
        "site_name = deschutes_temp_data['SITE_NAME'].unique()[0]\n",
        "param_name = deschutes_temp_data['parameter'].unique()[0]\n",
        "\n",
        "# Calculate stats\n",
        "mean_temp = deschutes_temp_data['value_F'].mean()\n",
        "min_temp = deschutes_temp_data['value_F'].min()\n",
        "max_temp = deschutes_temp_data['value_F'].max()\n",
        "\n",
        "# Linear regression for trend\n",
        "# x as ordinal dates\n",
        "x = deschutes_temp_data['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "y = deschutes_temp_data['value_F']\n",
        "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "# Calculate trend line y values\n",
        "slope_per_year = slope * 365.25 # convert to per year\n",
        "trend_line = slope * x + intercept\n",
        "\n",
        "# Compute RÂ² and p-value significance\n",
        "r_squared = r_value ** 2\n",
        "if p_value < 0.05:\n",
        "  significance = \"Significant (p < 0.05)\"\n",
        "else:\n",
        "  significance = \"Not Significant (p > 0.05)\"\n",
        "#significance = \"Significant\" if p_value < 0.05 else \"Not Significant\" # how the cool kids do it\n",
        "\n",
        "# List of stats that will be added to the plot\n",
        "stats_text = (\n",
        "    f\"Max: {max_temp:.1f}Â°F\\n\"\n",
        "    f\"Min: {min_temp:.1f}Â°F\\n\"\n",
        "    f\"Mean: {mean_temp:.1f}Â°F\\n\"\n",
        "    f\"Trend slope: {slope_per_year:.3f}Â°F/year\\n\"\n",
        "    f\"RÂ²: {r_squared:.3f}\\n\"\n",
        "    f\"p-value: {p_value:.4f}\\n\"\n",
        "    f\"{significance}\"\n",
        ")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14, 6)) # width, height\n",
        "plt.plot(deschutes_temp_data['date_time_new'], deschutes_temp_data['value_F'], # x, y\n",
        "         marker='o', markersize=3, # marker style\n",
        "         linestyle='-', linewidth=1, # line style\n",
        "         label='Observed Data') # legend label\n",
        "plt.plot(deschutes_temp_data['date_time_new'], trend_line, # trend line\n",
        "         linestyle='--', linewidth=2, color='red', # line style\n",
        "         label='Trend Line') # legend label\n",
        "\n",
        "# Add stats to plot\n",
        "plt.text(0.01, 0.98, stats_text, transform=plt.gca().transAxes,\n",
        "         verticalalignment='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
        "\n",
        "# Plot beautification\n",
        "plt.grid(True, linestyle='--', alpha=0.8) # background grid\n",
        "plt.title(f'{param_name} at {site_name}', fontsize=14, fontweight='bold') # plot title\n",
        "plt.ylabel(\"Water Temperature (Â°F)\", fontsize=12) # y-axis label\n",
        "plt.xticks(rotation=45) # rotate the x-axis labels\n",
        "plt.legend() # add legend\n",
        "plt.tight_layout() # auto adjust spacing to prevent overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UDp-W8g_IWmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Plots"
      ],
      "metadata": {
        "id": "0qv2PiizniMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a basic interactive plot of water temperature at every site on the Deschutes River\n",
        "# import plotly.express as px\n",
        "\n",
        "# Filter water temperature data and site names that begin with \"Deschutes\"\n",
        "filtered_data = wq_data[\n",
        "    (wq_data['parameter'] == param_name) & # 'Temperature, water'\n",
        "    (wq_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ].copy()\n",
        "\n",
        "# Plotting\n",
        "fig = px.line(\n",
        "    filtered_data,\n",
        "    x='date_time_new', # x data\n",
        "    y='value', # y data\n",
        "    color='SITE_NAME', # symbolize site name by color\n",
        "    title='Deschutes River Water Temperature'\n",
        ")\n",
        "\n",
        "# Layout styling for comparison\n",
        "fig.update_layout(hovermode='x unified') # enables value hovering for easy comparison\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0N9AiFH9n5-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy interactive plot of all WQ parameters at every site on the Deschutes River\n",
        "\n",
        "# Filter site names that begin with \"Deschutes\" and sort by datetime\n",
        "deschutes_data = wq_data[\n",
        "    (wq_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ]\n",
        "\n",
        "# Plotting\n",
        "fig_deschutes = px.line(\n",
        "    deschutes_data,\n",
        "    x='date_time_new',\n",
        "    y='value',\n",
        "    color='SITE_NAME',\n",
        "    facet_col='parameter', # each parameter gets its own plot\n",
        "    facet_col_wrap=3, # 3 plots per row\n",
        "    title='Deschutes River Water Quality Parameters',\n",
        "    height=800, # figure height\n",
        "    labels={ # customize label names for data hover\n",
        "        'date_time_new': 'Date',\n",
        "        'value': 'Measured Value',\n",
        "        'SITE_NAME': 'Site Name',\n",
        "        'unit': 'Unit'\n",
        "    },\n",
        "    hover_data={ # customize label values for data hover\n",
        "        'date_time_new': '|%m-%d-%Y', # reformat the datetime to mm/dd/yyyy\n",
        "        'value': ':.2f', # value with 2 decimals\n",
        "        'SITE_NAME': True, # inlcude site name in hover\n",
        "        'unit': True,\n",
        "        'parameter': False # do not include parameter name in hover\n",
        "    }\n",
        ")\n",
        "\n",
        "# Improve layout styling\n",
        "fig_deschutes.update_layout(\n",
        "    hovermode='x unified',\n",
        "    showlegend=True,\n",
        "    legend_title_text='Site Name', # update the legend title\n",
        "    title_font_size=18, # adjust plot title font size\n",
        "    margin=dict(l=40, r=40, t=80, b=40) # adjust plot margins (left, right, top, bottom)\n",
        ")\n",
        "\n",
        "# Make each facet plot's y-axis values independent from each other (needed since parameters have different measurement units)\n",
        "fig_deschutes.update_yaxes(title='', matches=None) # don't show y-axis label\n",
        "fig_deschutes.update_xaxes(title='') # don't show x-axis label\n",
        "\n",
        "# Clean up facet titles: remove \"parameter_unit=\" prefix\n",
        "for annotation in fig_deschutes.layout.annotations:\n",
        "    annotation.text = annotation.text.replace(\"parameter=\", \"\")\n",
        "\n",
        "fig_deschutes.show()"
      ],
      "metadata": {
        "id": "DJHMkoWlY2dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Automating Plot Generation and PDF Reports\n",
        "Up until this point, Excel would have been able to handle everything we just did (i.e., look at the data, filter by parameter and site, create plots). With Python (and programming in general), we can take this a step further by automating those redundant processes that are done in Excel. For example, we can write a script to plot a timeseries of all WQ parameters at each stream site location and then save to a PDF."
      ],
      "metadata": {
        "id": "-AzNrsKU-zys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ›‘ Task 3: Fill in the blanks (XXX) to generate a PDF report of WQ parameter time-series plots at each stream site location"
      ],
      "metadata": {
        "id": "2ojSYZADzg8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy, multi-facet plot of all WQ parameters for each stream site location and save to a single PDF (takes approx. 4-5 minutes to run)\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "# import numpy as np\n",
        "\n",
        "# Toggle switch for running the cell\n",
        "run_cell = True # True or False\n",
        "\n",
        "# Output file\n",
        "output_pdf = \"WaterQuality_SiteParameter_Trends.pdf\"\n",
        "\n",
        "if run_cell:\n",
        "  # Create PDF file to save all plots; each site gets a single PDF page\n",
        "  with PdfPages(output_pdf) as pdf:\n",
        "      # Loop through each site\n",
        "      for site_name, site_df in wq_data.groupby('SITE_NAME'):\n",
        "          parameters = site_df['parameter'].unique()\n",
        "\n",
        "          # Setup multi-facet plot layout\n",
        "          n_params = len(parameters)\n",
        "          ncols = 2\n",
        "          nrows = int(np.ceil(n_params / ncols))\n",
        "          fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, nrows * 4))\n",
        "          axes = axes.flatten()\n",
        "\n",
        "          # Loop through each parameter, apply regression, calculate stats, and plot\n",
        "          for i, param_name in enumerate(parameters):\n",
        "              ax = axes[i]\n",
        "              param_df = site_df[site_df['parameter'] == param_name].copy()\n",
        "              param_df = param_df.sort_values(by=\"date_time_new\")\n",
        "\n",
        "              # Convert temperature from C to F\n",
        "              if \"temp\" in param_name.lower():\n",
        "                  param_df['value_plot'] = param_df['value'] * 9/5 + 32\n",
        "                  y_label = \"Temperature (Â°F)\"\n",
        "              else:\n",
        "                  param_df['value_plot'] = param_df['value']\n",
        "                  y_label = f\"{param_name} ({param_df['unit'].iloc[0] if 'unit' in param_df.columns else ''})\"\n",
        "\n",
        "              # Data for regression\n",
        "              param_df = param_df.dropna(subset=['date_time_new', 'value_plot']) # remove NA values for regression analysis\n",
        "              x = param_df['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "              y = param_df['value_plot']\n",
        "              n_points = len(y)\n",
        "\n",
        "              # Check data sufficiency\n",
        "              if n_points >= 3:\n",
        "                  slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "                  slope_per_year = slope * 365.25\n",
        "                  r_squared = r_value ** 2\n",
        "                  trend_line = slope * x + intercept\n",
        "                  significance = \"Significant (p < 0.05)\" if p_value < 0.05 else \"Not Significant\"\n",
        "              else:\n",
        "                  slope_per_year = np.nan\n",
        "                  r_squared = np.nan\n",
        "                  p_value = np.nan\n",
        "                  trend_line = [np.nan] * len(x)\n",
        "                  significance = \"Insufficient data for regression\"\n",
        "\n",
        "              # Summary statistics\n",
        "              mean_val = y.mean()\n",
        "              min_val = y.min()\n",
        "              max_val = y.max()\n",
        "\n",
        "              # Stats text\n",
        "              if np.isnan(p_value):\n",
        "                  p_str = \"N/A\"\n",
        "              else:\n",
        "                  p_str = f\"{p_value:.4f}\"\n",
        "\n",
        "              stats_text = (\n",
        "                  f\"n = {n_points}\\n\"\n",
        "                  f\"Max: {max_val:.1f}\\n\"\n",
        "                  f\"Min: {min_val:.1f}\\n\"\n",
        "                  f\"Mean: {mean_val:.1f}\\n\"\n",
        "                  f\"Trend: {slope_per_year:.3f}/yr\\n\"\n",
        "                  f\"RÂ²: {r_squared:.3f}\\n\"\n",
        "                  f\"p: {p_str}\\n\"\n",
        "                  f\"{significance}\"\n",
        "              )\n",
        "\n",
        "              # Plotting\n",
        "              ax.plot(param_df['date_time_new'], y, marker='o', markersize=3,\n",
        "                      linestyle='-', linewidth=1, label='Observed')\n",
        "              ax.plot(param_df['date_time_new'], trend_line, linestyle='--',\n",
        "                      linewidth=2, color='red', label='Trend')\n",
        "              ax.text(0.01, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
        "                      verticalalignment='top',\n",
        "                      bbox=dict(facecolor='white', alpha=0.7, edgecolor='gray'))\n",
        "              ax.set_title(f\"{param_name}\", fontsize=11, fontweight='bold')\n",
        "              ax.set_ylabel(y_label)\n",
        "              ax.grid(True, linestyle='--', alpha=0.6)\n",
        "              ax.legend(fontsize=8)\n",
        "              ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "          # Remove unused subplots\n",
        "          for j in range(i + 1, len(axes)):\n",
        "              fig.delaxes(axes[j])\n",
        "\n",
        "          # Layout and save\n",
        "          fig.suptitle(f\"Water Quality Trends at {site_name}\", fontsize=14, fontweight='bold')\n",
        "          plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "          pdf.savefig(fig)\n",
        "          plt.close(fig)\n",
        "\n",
        "  print(f\"All plots saved to: {output_pdf}\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping this cell.\")"
      ],
      "metadata": {
        "id": "Ps1mxoxuRM9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 9. Generating Maps\n",
        "Since the stream site location data has a latitude and longitude column, we can plot the locations on an interactive map."
      ],
      "metadata": {
        "id": "kQESUKPdQRWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a basic location map of stream site locations\n",
        "\n",
        "site_map = px.scatter_mapbox(\n",
        "    sites, # stream site location data\n",
        "    lat=\"LAT\", # latitude column\n",
        "    lon=\"LON\", # longitude column\n",
        "    hover_name=\"SITE_NAME\", # popup label that appears when hovered over\n",
        "    hover_data=\"AquaticLifeUse\", # popup data that appears when hovered over\n",
        "    title=\"Stream Site Monitoring Locations\", # map title\n",
        "    mapbox_style=\"open-street-map\", # basemap; other options - \"carto-positron\", \"carto-darkmatter\"\n",
        ")\n",
        "\n",
        "site_map.show(config={'scrollZoom': True}) # show map (and enable scroll zoom for convience)"
      ],
      "metadata": {
        "id": "krq2jU1waXsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct geospatial analysis and generate maps of the wq_data, we need to join/merge the WQ data with the stream site location data\n",
        "merged_data = pd.merge(\n",
        "    wq_data,\n",
        "    sites[['SITE_NAME', 'LAT', 'LON', 'AquaticLifeUse']], # keep only the site name, latitude, longitude, and aquatic life use columns\n",
        "    on='SITE_NAME', # merge the dataframes based on a common column\n",
        "    how='left' # keep all rows in the wq_data and only matching rows in the sites data\n",
        ")\n",
        "\n",
        "merged_data.columns # show the dataframe column names"
      ],
      "metadata": {
        "id": "3A1pkzcO8QVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a map showing the distribution of water temperature at stream site locations\n",
        "\n",
        "# Filter out stream temperature data\n",
        "stream_temp_data = merged_data[\n",
        "    (merged_data['parameter'] == param_name) # 'Temperature, water'\n",
        "    ].copy()\n",
        "\n",
        "# Calculate monthly average stream temperature for all sites\n",
        "stream_temp_data[\"year_month\"] = stream_temp_data[\"date_time_new\"].dt.to_period(\"M\").dt.strftime(\"%Y-%m\") # add a year_month column so we can group by month\n",
        "monthly_avg_temp = (\n",
        "    stream_temp_data\n",
        "    .groupby([\"SITE_NAME\", \"LAT\", \"LON\", \"year_month\", \"parameter\", \"unit\"], as_index=False)\n",
        "    .agg(mean_temp=(\"value\", \"mean\"))\n",
        ").sort_values(by=\"year_month\")\n",
        "\n",
        "# Find min and max stream temperautre values\n",
        "vmin = monthly_avg_temp['mean_temp'].min()\n",
        "vmax = monthly_avg_temp['mean_temp'].max()\n",
        "\n",
        "# Plotting\n",
        "stream_temp_map = px.scatter_mapbox(\n",
        "    monthly_avg_temp,\n",
        "    lat=\"LAT\",\n",
        "    lon=\"LON\",\n",
        "    color=\"mean_temp\", # symbolize points by stream temp value\n",
        "    range_color=(vmin, vmax), # color range based on min/max temp values\n",
        "    animation_frame=\"year_month\", # animate points by date/time\n",
        "    hover_name=\"SITE_NAME\",\n",
        "    hover_data={\n",
        "        \"year_month\": \"|%Y-%m\", # show datetime in hover\n",
        "        \"parameter\": True, # show parameter\n",
        "        \"mean_temp\": \":.2f\", # show value with 2 decimals\n",
        "        \"unit\": True, # show parameter unit\n",
        "        \"LAT\": False, # DO NOT show LAT\n",
        "        \"LON\": False # DO NOT show LONG\n",
        "    },\n",
        "    title=\"Stream Temperature at Monitoring Locations in Thurston County\",\n",
        "    height=800, # map height\n",
        "    zoom=9, # set zoom level\n",
        "    mapbox_style=\"carto-positron\" # better basemap for viewing symbol colors\n",
        ")\n",
        "\n",
        "# Update map aesthetics\n",
        "stream_temp_map.update_traces(marker=dict(size=12)) # increase size of points on map\n",
        "\n",
        "stream_temp_map.show(config={'scrollZoom': True}) # show map (and enable scroll zoom for convience)"
      ],
      "metadata": {
        "id": "dSi3NOMVv5Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 10. Generating Data Dashboards"
      ],
      "metadata": {
        "id": "Ay9LplAga8fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages that aren't preinstalled in Colab\n",
        "!pip install dash\n",
        "\n",
        "from dash import Dash, dcc, html, Input, Output"
      ],
      "metadata": {
        "id": "NqN9Hv9BN2vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Generate a data dashboard\n",
        "\n",
        "# Get unique parameter names and sort alphabetically\n",
        "param_options = sorted(merged_data[\"parameter\"].dropna().unique())\n",
        "\n",
        "# Initialize the app\n",
        "app = Dash(__name__)\n",
        "\n",
        "# App layout (User-Interface) --------------------------------------------------\n",
        "app.layout = html.Div([\n",
        "    # Dropdown menu\n",
        "    html.Div([\n",
        "        html.Label(\"Select Parameter:\", style={\"fontWeight\": \"bold\"}),\n",
        "        dcc.Dropdown(\n",
        "            id=\"param\",\n",
        "            options=[{\"label\": p, \"value\": p} for p in param_options],\n",
        "            value=param_options[0],\n",
        "            clearable=False,\n",
        "            style={\"width\": \"100%\"}\n",
        "        ),\n",
        "    ], style={\"width\": \"25%\", \"margin\": \"10px\"}),\n",
        "\n",
        "    # Time-Series Plot and Map\n",
        "    html.Div([\n",
        "        html.Div([\n",
        "            dcc.Graph(\n",
        "                id=\"timeseries\",\n",
        "                style={\"width\": \"100%\", \"height\": \"90vh\"},\n",
        "                config={\"responsive\": True}\n",
        "            )\n",
        "        ], style={\"flex\": \"1.5\"}),\n",
        "\n",
        "        html.Div([\n",
        "            dcc.Graph(\n",
        "                id=\"map\",\n",
        "                style={\"width\": \"100%\", \"height\": \"90vh\"},\n",
        "                config={\"responsive\": True}\n",
        "            )\n",
        "        ], style={\"flex\": \"1\"})\n",
        "    ], style={\n",
        "        \"display\": \"flex\",\n",
        "        \"flexDirection\": \"row\",\n",
        "        \"width\": \"100%\",\n",
        "        \"alignItems\": \"stretch\",\n",
        "    })\n",
        "])\n",
        "\n",
        "# Callback to update plot and map ----------------------------------------------\n",
        "@app.callback(\n",
        "    Output(\"timeseries\", \"figure\"),\n",
        "    Output(\"map\", \"figure\"),\n",
        "    Input(\"param\", \"value\")\n",
        ")\n",
        "\n",
        "# Update plot and map based on user selection from dropdown menu\n",
        "def update_dashboard(param):\n",
        "    df = merged_data[merged_data[\"parameter\"] == param].copy()\n",
        "    df[\"year_month_dt\"] = df[\"date_time_new\"].dt.to_period(\"M\").dt.to_timestamp()\n",
        "    df[\"year_month\"] = df[\"date_time_new\"].dt.strftime(\"%Y-%m\")\n",
        "\n",
        "    # Monthly averages\n",
        "    monthly_avg = (\n",
        "        df.groupby([\"SITE_NAME\", \"LAT\", \"LON\", \"year_month\", \"year_month_dt\"], as_index=False)\n",
        "          .agg(mean_value=(\"value\", \"mean\"))\n",
        "          .sort_values(\"year_month_dt\")\n",
        "    )\n",
        "\n",
        "    ## Time-series line plot ---------------------------------------------------\n",
        "    ts_fig = px.line(\n",
        "        monthly_avg, x=\"year_month\", y=\"mean_value\", color=\"SITE_NAME\",\n",
        "        title=f\"{param} â€” Monthly Trend by Site\", height=800,\n",
        "        category_orders={\"SITE_NAME\": sorted(monthly_avg[\"SITE_NAME\"].unique())}\n",
        "    )\n",
        "    ts_fig.update_layout(\n",
        "        autosize=True,\n",
        "        xaxis_title=\"\",\n",
        "        margin=dict(t=50, l=20, r=20, b=100),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"top\",\n",
        "            y=-0.2,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5,\n",
        "            title=None,\n",
        "            font=dict(size=10)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    ## Map (animated) ----------------------------------------------------------\n",
        "    vmin, vmax = monthly_avg[\"mean_value\"].min(), monthly_avg[\"mean_value\"].max() # min and max of parameter data\n",
        "\n",
        "    # Plotting\n",
        "    map_fig = px.scatter_mapbox(\n",
        "        monthly_avg, lat=\"LAT\", lon=\"LON\", color=\"mean_value\",\n",
        "        range_color=(vmin, vmax), animation_frame=\"year_month_dt\",\n",
        "        hover_name=\"SITE_NAME\", mapbox_style=\"carto-positron\",\n",
        "        zoom=8, height=800\n",
        "    )\n",
        "    map_fig.update_traces(marker=dict(size=12))\n",
        "    map_fig.update_layout(\n",
        "        autosize=True,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        legend=dict(\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"top\",\n",
        "            y=0,\n",
        "            xanchor=\"center\",\n",
        "            x=0.5,\n",
        "            title=None\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return ts_fig, map_fig\n",
        "\n",
        "# Run app ----------------------------------------------------------------------\n",
        "app.run(mode=\"inline\") # run app within Colab"
      ],
      "metadata": {
        "id": "9hv2Q7SyOIsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}