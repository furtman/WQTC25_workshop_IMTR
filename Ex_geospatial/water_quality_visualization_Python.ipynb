{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furtman/WQTC25_workshop_IMTR/blob/main/Ex_geospatial/water_quality_visualization_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PCW01: From Data Management to Data Analysis — A Technical Deep-Dive**\n",
        "AWWA WQTC 2025, November 9-13th, Tacoma WA\n",
        "## **Water Quality Data Visualization using Google Colab and Python**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook walks through building and running an interactive data visualization dashboard inside a **Google Colab** workspace using the **Python** programming language. Users will learn how to load, inspect, and analyze data from a spreadsheet, generate static and interactive visualizations of time series plots and maps, and compile the visualizations into a PDF report and an easy-to-use dashboard that synthesizes data into single webpage.\n",
        "\n",
        "The data used in this notebook is publicly available at Thurston County:\n",
        "1.   Water Quality Data: https://github.com/HerreraEnvironmental/23-08082-000-TC-WQ-Dashboard/blob/main/wqp_data.csv\n",
        "2.   Stream Site Locations and Aquatic Use Data: https://github.com/HerreraEnvironmental/23-08082-000-TC-WQ-Dashboard/blob/main/outputs/streams_sites.csv\n",
        "\n",
        "An example of a fully-functional WQ data dashboard created using Shiny and R - Thurston County Streams Water Quality Dashboard: https://www.thurstoncountywa.gov/streams-water-quality-dashboard\n",
        "\n",
        "---\n",
        "\n",
        "Notebook Table of Contents:\n",
        "1.   Setup Python Runtime\n",
        "2.   Load Python Libraries\n",
        "3.   Upload Files to Google Colab\n",
        "4.   Load and Inspect Data\n",
        "5.   Data Cleaning and Processing\n",
        "6.   Generating Summary Statistics\n",
        "7.   Generating Plots\n",
        "8.   Generating Multiple Plots\n",
        "9.   Generating Maps"
      ],
      "metadata": {
        "id": "KoemvlApqdWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 1. Setup Python Runtime\n",
        "Prior to installing any packages, change the ***runtime type*** to ***Python 3*** if it isn't already selected. Google Colab comes with several popular python packages pre-installed, such as *pandas* and *matplotlib*, which are commonly used to .\n",
        "\n"
      ],
      "metadata": {
        "id": "SOwfXpnOxRtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2. Load Python Libraries\n",
        "In order to use the functions within each library, we need to load them into the notebook."
      ],
      "metadata": {
        "id": "iafWRDeWxpjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the Python libraries that will be used in this notebook\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import linregress\n",
        "import plotly.express as px\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "#import contextily as ctx\n",
        "#from jupyter_dash import JupyterDash\n",
        "#from dash import dcc, html, Input, Output"
      ],
      "metadata": {
        "id": "es0shomvxxdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 3. Upload Files to Google Colab\n",
        "Since Google Colab is run on Linux cloud machines, we need to transfer the files from our PC (Windows, macOS, etc.) to the Google Colab workspace."
      ],
      "metadata": {
        "id": "qNz11c3KpuLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose files to upload; By default, uploaded files are saved in the \"Files/content/\" folder within the Google Colab workspace\n",
        "# from google.colab import files\n",
        "uploaded_files = files.upload()"
      ],
      "metadata": {
        "id": "uIPbdrlFsAmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or we can download directly from the internet\n",
        "# URLs of water quality data (Thurston County)\n",
        "sites_url = \"https://raw.githubusercontent.com/HerreraEnvironmental/23-08082-000-TC-WQ-Dashboard/main/outputs/streams_sites.csv\"\n",
        "data_url = \"https://raw.githubusercontent.com/HerreraEnvironmental/23-08082-000-TC-WQ-Dashboard/main/wqp_data.csv\""
      ],
      "metadata": {
        "id": "PeCnMrDlyC9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 4. Load and Inspect Data\n",
        "\n",
        "Read in the CSV files to the notebook as variables called `sites` and `wq_data`."
      ],
      "metadata": {
        "id": "rbpSAyCQyR_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in stream site location data and inspect\n",
        "# import pandas as pd\n",
        "sites = pd.read_csv(\"streams_sites.csv\")\n",
        "print('This is the stream site location data:') # output a message to the console\n",
        "sites # show data"
      ],
      "metadata": {
        "id": "otTeWFqL57d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in water quality data and inspect\n",
        "wq_data = pd.read_csv(\"wqp_data.csv\")\n",
        "print(\"This is the water quality data associated with each stream site:\")\n",
        "wq_data"
      ],
      "metadata": {
        "id": "Y0Xt-Hwb5vM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show some general info about the data types of each column in the water quality data\n",
        "wq_data.info()"
      ],
      "metadata": {
        "id": "y6z_WWzZf5C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the unique stream site locations and parameter names\n",
        "print(\"The unique stream site locations are:\", sites['SITE_NAME'].unique())\n",
        "print(\"\\n\") # add a line break so it's easier to see the different outputs\n",
        "print(\"The unique parameter names are:\", wq_data['parameter'].unique())"
      ],
      "metadata": {
        "id": "O19q3WhprM_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 5. Data Cleaning and Processing"
      ],
      "metadata": {
        "id": "UFsRaVj57jEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct timeseries analysis and plot the WQ data, we need to change the 'date_time' column to a datetime data type and sort by date\n",
        "wq_data['date_time_new'] = pd.to_datetime(wq_data['date_time'], format='mixed')\n",
        "wq_data = wq_data.sort_values(by='date_time_new') # sort values by datetime\n",
        "wq_data.info()"
      ],
      "metadata": {
        "id": "KYGA65zy7l66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to conduct geospatial analysis and generate maps, we need to join/merge the WQ data with the stream site location data\n",
        "merged_data = pd.merge(\n",
        "    wq_data,\n",
        "    sites[['SITE_NAME', 'LAT', 'LON', 'AquaticLifeUse']], # keep only the site name, latitude, longitude, and aquatic life use columns\n",
        "    on='SITE_NAME', # merge the dataframes based on a common column\n",
        "    how='left' # keep all rows in the wq_data and only matching rows in the sites data\n",
        ")\n",
        "\n",
        "merged_data.columns # show the dataframe column names"
      ],
      "metadata": {
        "id": "3A1pkzcO8QVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Generating Summary Statistics"
      ],
      "metadata": {
        "id": "8A1EWwgS2J8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some basic summary stats of observed WQ values for each site and parameter pairing\n",
        "summary_stats = merged_data.groupby(['SITE_NAME', 'parameter'])['value'].agg(['count','mean','median','min','max']).reset_index()\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "CJzv-GeB2JpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View summary stats for a specific site\n",
        "summary_stats[summary_stats['SITE_NAME'] == 'Deschutes @ Tumwater Falls Park']"
      ],
      "metadata": {
        "id": "j0I6ddDJ49kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 7. Generating Plots"
      ],
      "metadata": {
        "id": "Zk0IV2l1A38G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Static Plots"
      ],
      "metadata": {
        "id": "UV_iYU_lnptV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a timeseries plot of a WQ parameter for a specific site\n",
        "# Filter the data for a specific site name and parameter (e.g., water temperature)\n",
        "site_name = 'Deschutes @ Tumwater Falls Park'\n",
        "param_name = 'Temperature, water'\n",
        "site_temp_data = merged_data[ # filter out data for specific parameter and site\n",
        "    (merged_data['SITE_NAME'] == site_name) &\n",
        "    (merged_data['parameter'] == param_name)\n",
        "    ].copy() # save to a new dataframe\n",
        "site_temp_data = site_temp_data.sort_values(by='date_time_new') # sort the data by date/time\n",
        "site_temp_data"
      ],
      "metadata": {
        "id": "gg-mR-M26xv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic line plot\n",
        "# import matplotlib.pyplot as plt\n",
        "plt.plot(site_temp_data['date_time_new'], site_temp_data['value']) # x, y\n",
        "plt.xlabel('Date') # x-axis label\n",
        "plt.ylabel(param_name) # y-axis label\n",
        "plt.title(f'Parameter: {param_name} | Site: {site_name}') # plot title\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eSzXstxzCnTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fancy plot with summary stats and trend line\n",
        "# from scipy.stats import linregress\n",
        "\n",
        "# Convert temperature from C to F\n",
        "site_temp_data['value_F'] = site_temp_data['value'] * 9/5 + 32\n",
        "\n",
        "# Calculate stats\n",
        "mean_temp = site_temp_data['value_F'].mean()\n",
        "min_temp = site_temp_data['value_F'].min()\n",
        "max_temp = site_temp_data['value_F'].max()\n",
        "\n",
        "# Linear regression for trend\n",
        "# x as ordinal dates\n",
        "x = site_temp_data['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "y = site_temp_data['value_F']\n",
        "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "\n",
        "# Calculate trend line y values\n",
        "slope_per_year = slope * 365.25 # convert to per year\n",
        "trend_line = slope * x + intercept\n",
        "\n",
        "# Compute R² and p-value significance\n",
        "r_squared = r_value ** 2\n",
        "if p_value < 0.05:\n",
        "  significance = \"Significant (p < 0.05)\"\n",
        "else:\n",
        "  significance = \"Not Significant (p > 0.05)\"\n",
        "#significance = \"Significant\" if p_value < 0.05 else \"Not Significant\" # how the cool kids do it\n",
        "\n",
        "# List of stats that will be added to the plot\n",
        "stats_text = (\n",
        "    f\"Max: {max_temp:.1f}°F\\n\"\n",
        "    f\"Min: {min_temp:.1f}°F\\n\"\n",
        "    f\"Mean: {mean_temp:.1f}°F\\n\"\n",
        "    f\"Trend slope: {slope_per_year:.3f}°F/year\\n\"\n",
        "    f\"R²: {r_squared:.3f}\\n\"\n",
        "    f\"p-value: {p_value:.4f}\\n\"\n",
        "    f\"{significance}\"\n",
        ")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14, 6)) # width, height\n",
        "plt.plot(site_temp_data['date_time_new'], site_temp_data['value_F'], # x, y\n",
        "         marker='o', markersize=3, # marker style\n",
        "         linestyle='-', linewidth=1, # line style\n",
        "         label='Observed Data') # legend label\n",
        "plt.plot(site_temp_data['date_time_new'], trend_line, # trend line\n",
        "         linestyle='--', linewidth=2, color='red', # line style\n",
        "         label='Trend Line') # legend label\n",
        "\n",
        "# Add stats to plot\n",
        "plt.text(0.01, 0.98, stats_text, transform=plt.gca().transAxes,\n",
        "         verticalalignment='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray'))\n",
        "\n",
        "# Plot beautification\n",
        "plt.grid(True, linestyle='--', alpha=0.8) # background grid\n",
        "plt.title(f'{param_name} at {site_name}', fontsize=14, fontweight='bold') # plot title\n",
        "plt.ylabel(\"Water Temperature (°F)\", fontsize=12) # y-axis label\n",
        "plt.xticks(rotation=45) # rotate the x-axis labels\n",
        "plt.legend() # add legend\n",
        "plt.tight_layout() # auto adjust spacing to prevent overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UDp-W8g_IWmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interactive Plots"
      ],
      "metadata": {
        "id": "0qv2PiizniMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a basic interactive plot of water temperature at every site on the Deschutes River\n",
        "# import plotly.express as px\n",
        "\n",
        "# Filter water temperature data and site names that begin with \"Deschutes\"\n",
        "filtered_data = merged_data[\n",
        "    (merged_data['parameter'] == param_name) & # 'Temperature, water'\n",
        "    (merged_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ].copy()\n",
        "\n",
        "# Sort by datetime\n",
        "filtered_data = filtered_data.sort_values(by='date_time_new')\n",
        "\n",
        "# Plotting\n",
        "fig = px.line(\n",
        "    filtered_data,\n",
        "    x='date_time_new', # x data\n",
        "    y='value', # y data\n",
        "    color='SITE_NAME', # symbolize site name by color\n",
        "    title='Deschutes River Water Temperature'\n",
        ")\n",
        "\n",
        "# Layout styling for comparison\n",
        "fig.update_layout(hovermode='x unified') # enables value hovering for easy comparison\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0N9AiFH9n5-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy interactive plot of all WQ parameters at every site on the Deschutes River\n",
        "\n",
        "# Filter site names that begin with \"Deschutes\" and sort by datetime\n",
        "deschutes_data = merged_data[\n",
        "    (merged_data['SITE_NAME'].str.startswith('Deschutes'))\n",
        "    ].sort_values(by='date_time_new').copy()\n",
        "\n",
        "# Plotting\n",
        "fig_deschutes = px.line(\n",
        "    deschutes_data,\n",
        "    x='date_time_new',\n",
        "    y='value',\n",
        "    color='SITE_NAME',\n",
        "    facet_col='parameter', # each parameter gets its own plot\n",
        "    facet_col_wrap=3, # 3 plots per row\n",
        "    title='Deschutes River Water Quality Parameters',\n",
        "    height=800, # figure height\n",
        "    labels={ # customize label names for data hover\n",
        "        'date_time_new': 'Date',\n",
        "        'value': 'Measured Value',\n",
        "        'SITE_NAME': 'Site Name',\n",
        "        'unit': 'Unit'\n",
        "    },\n",
        "    hover_data={ # customize label values for data hover\n",
        "        'date_time_new': '|%m-%d-%Y', # reformat the datetime to mm/dd/yyyy\n",
        "        'value': ':.2f', # value with 2 decimals\n",
        "        'SITE_NAME': True, # inlcude site name in hover\n",
        "        'unit': True,\n",
        "        'parameter': False # do not include parameter name in hover\n",
        "    }\n",
        ")\n",
        "\n",
        "# Improve layout styling\n",
        "fig_deschutes.update_layout(\n",
        "    hovermode='x unified',\n",
        "    showlegend=True,\n",
        "    legend_title_text='Site Name', # update the legend title\n",
        "    title_font_size=18, # adjust plot title font size\n",
        "    margin=dict(l=40, r=40, t=80, b=40) # adjust plot margins (left, right, top, bottom)\n",
        ")\n",
        "\n",
        "# Make each facet plot's y-axis values independent from each other (needed since parameters have different measurement units)\n",
        "fig_deschutes.update_yaxes(title='', matches=None) # don't show y-axis label\n",
        "fig_deschutes.update_xaxes(title='') # don't show x-axis label\n",
        "\n",
        "# Clean up facet titles: remove \"parameter_unit=\" prefix\n",
        "for annotation in fig_deschutes.layout.annotations:\n",
        "    annotation.text = annotation.text.replace(\"parameter=\", \"\")\n",
        "\n",
        "fig_deschutes.show()"
      ],
      "metadata": {
        "id": "DJHMkoWlY2dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Generating Multiple Plots\n",
        "Up until this point, Excel would have been able to handle everything we just did (i.e., look at the data, filter by parameter and site, create plots). With Python (and programming in general), we can take this a step further by automating those redundant processes that are done in Excel. For example, we can write a script to plot a timeseries of all WQ parameters at each stream site location and then save to a PDF."
      ],
      "metadata": {
        "id": "-AzNrsKU-zys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a fancy, multi-facet plot of all WQ parameters for each stream site location and save to a single PDF (takes approx. 4-5 minutes to run)\n",
        "# import numpy as np\n",
        "# from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "# Output file\n",
        "output_pdf = \"WaterQuality_SiteParameter_Trends.pdf\"\n",
        "\n",
        "# Create PDF file to save all plots; each site gets a single PDF page\n",
        "with PdfPages(output_pdf) as pdf:\n",
        "    # Loop through each site\n",
        "    for site_name, site_df in merged_data.groupby('SITE_NAME'):\n",
        "        parameters = site_df['parameter'].unique()\n",
        "\n",
        "        # Setup multi-facet plot layout\n",
        "        n_params = len(parameters)\n",
        "        ncols = 2\n",
        "        nrows = int(np.ceil(n_params / ncols))\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, nrows * 4))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        # Loop through each parameter, apply regression, calculate stats, and plot\n",
        "        for i, param_name in enumerate(parameters):\n",
        "            ax = axes[i]\n",
        "            param_df = site_df[site_df['parameter'] == param_name].copy()\n",
        "            param_df = param_df.sort_values(by=\"date_time_new\")\n",
        "\n",
        "            # Convert temperature from C to F\n",
        "            if \"temp\" in param_name.lower():\n",
        "                param_df['value_plot'] = param_df['value'] * 9/5 + 32\n",
        "                y_label = \"Temperature (°F)\"\n",
        "            else:\n",
        "                param_df['value_plot'] = param_df['value']\n",
        "                y_label = f\"{param_name} ({param_df['unit'].iloc[0] if 'unit' in param_df.columns else ''})\"\n",
        "\n",
        "            # Data for regression\n",
        "            x = param_df['date_time_new'].map(lambda dt: dt.toordinal())\n",
        "            y = param_df['value_plot']\n",
        "            n_points = len(y)\n",
        "\n",
        "            # Check data sufficiency\n",
        "            if n_points >= 3:\n",
        "                slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
        "                slope_per_year = slope * 365.25\n",
        "                r_squared = r_value ** 2\n",
        "                trend_line = slope * x + intercept\n",
        "                significance = \"Significant (p < 0.05)\" if p_value < 0.05 else \"Not Significant\"\n",
        "            else:\n",
        "                slope_per_year = np.nan\n",
        "                r_squared = np.nan\n",
        "                p_value = np.nan\n",
        "                trend_line = [np.nan] * len(x)\n",
        "                significance = \"Insufficient data for regression\"\n",
        "\n",
        "            # Summary statistics\n",
        "            mean_val = y.mean()\n",
        "            min_val = y.min()\n",
        "            max_val = y.max()\n",
        "\n",
        "            # Stats text\n",
        "            if np.isnan(p_value):\n",
        "                p_str = \"N/A\"\n",
        "            else:\n",
        "                p_str = f\"{p_value:.4f}\"\n",
        "\n",
        "            stats_text = (\n",
        "                f\"n = {n_points}\\n\"\n",
        "                f\"Max: {max_val:.1f}\\n\"\n",
        "                f\"Min: {min_val:.1f}\\n\"\n",
        "                f\"Mean: {mean_val:.1f}\\n\"\n",
        "                f\"Trend: {slope_per_year:.3f}/yr\\n\"\n",
        "                f\"R²: {r_squared:.3f}\\n\"\n",
        "                f\"p: {p_str}\\n\"\n",
        "                f\"{significance}\"\n",
        "            )\n",
        "\n",
        "            # Plotting\n",
        "            ax.plot(param_df['date_time_new'], y, marker='o', markersize=3,\n",
        "                    linestyle='-', linewidth=1, label='Observed')\n",
        "            ax.plot(param_df['date_time_new'], trend_line, linestyle='--',\n",
        "                    linewidth=2, color='red', label='Trend')\n",
        "            ax.text(0.01, 0.98, stats_text, transform=ax.transAxes, fontsize=9,\n",
        "                    verticalalignment='top',\n",
        "                    bbox=dict(facecolor='white', alpha=0.7, edgecolor='gray'))\n",
        "            ax.set_title(f\"{param_name}\", fontsize=11, fontweight='bold')\n",
        "            ax.set_ylabel(y_label)\n",
        "            ax.grid(True, linestyle='--', alpha=0.6)\n",
        "            ax.legend(fontsize=8)\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Remove unused subplots\n",
        "        for j in range(i + 1, len(axes)):\n",
        "            fig.delaxes(axes[j])\n",
        "\n",
        "        # Layout and save\n",
        "        fig.suptitle(f\"Water Quality Trends at {site_name}\", fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "print(f\"All plots saved to: {output_pdf}\")"
      ],
      "metadata": {
        "id": "Ps1mxoxuRM9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Generating Maps"
      ],
      "metadata": {
        "id": "kQESUKPdQRWR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}